{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Text_Generation_with_ngram_modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishanthedev/Python/blob/master/Text_Generation_with_ngram_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u88Mht3AXHh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from tying import list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWTcOI1nXHh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = list(pd.read_csv('yelp.csv')['text'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MahsN7OYXHh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, s in enumerate(sentences):\n",
        "    sentences[i] = s.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR0KK_CvftrB",
        "colab_type": "text"
      },
      "source": [
        "python\n",
        "model ={\n",
        "  \"food\" : {\n",
        "    # probability given that the given that my prior given information is the text food\n",
        "\n",
        "  }\n",
        "  \"food is\"\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZXdlQUkXHiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import reuters\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXiFwB1WXHiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "99749fea-3160-4c01-b2c3-638495ca6da4"
      },
      "source": [
        "# Create a placeholder for model\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# Count frequency of co-occurance  \n",
        "for sentence in sentences:\n",
        "  # sentence: List[Token]\n",
        "  #print(sentence)\n",
        "  for w1,w2,w3 in trigrams(sentence,  pad_left= True, pad_right = True):\n",
        "    model[(w1,w2)][w3] += 1\n",
        "print(model[(\"on\",\"it\")])    \n",
        " \n",
        "# Let's transform the counts to probabilities\n",
        "for w1_w2 in model:\n",
        "  total_count=float(\n",
        "      sum(model[w1_w2].values())\n",
        "  )\n",
        "  for w3 in model[w1_w2]:\n",
        "    model[w1_w2][w3]/= total_count"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function <lambda>.<locals>.<lambda> at 0x7f59cf4cad90>, {'and': 14, '(like': 1, 'like': 3, 'will': 1, 'was': 8, 'on': 1, 'doing': 1, 'or': 3, 'Jaws': 1, 'about': 1, 'but,': 1, 'now,': 1, 'then': 1, 'as': 2, 'that': 3, 'went.': 1, 'melted': 1, 'altogether.': 1, 'from': 2, 'so': 4, 'after': 1, 'though': 1, 'here.': 1, 'just': 1, 'too)': 1, 'immediately': 1, '-': 1, '(if': 1, 'really': 1, 'feels': 1, 'too.': 1, 'is': 1, 'our': 1, 'because': 3, 'including': 1, 'but': 1, 'to': 2, 'served': 1, 'ready': 1, '10,000': 1, 'yet': 1, 'for': 1, 'which': 1, 'first.': 1, 'poolside.': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1WSL_aRoXHiG",
        "colab_type": "code",
        "outputId": "98310230-cec7-4c30-c235-b9fec6d6ba4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "dict(model[\"beer\",\"is\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'$2.00': 0.03571428571428571,\n",
              " 'a': 0.03571428571428571,\n",
              " 'also': 0.07142857142857142,\n",
              " 'astounding': 0.03571428571428571,\n",
              " 'awesome.': 0.03571428571428571,\n",
              " 'cold.': 0.03571428571428571,\n",
              " 'even': 0.03571428571428571,\n",
              " 'excellent,': 0.03571428571428571,\n",
              " 'fantastic,': 0.03571428571428571,\n",
              " 'fine': 0.03571428571428571,\n",
              " 'fresh': 0.03571428571428571,\n",
              " 'great': 0.03571428571428571,\n",
              " 'great,': 0.07142857142857142,\n",
              " 'just': 0.03571428571428571,\n",
              " 'legendary': 0.03571428571428571,\n",
              " 'like...the': 0.03571428571428571,\n",
              " 'on': 0.03571428571428571,\n",
              " 'poured,': 0.03571428571428571,\n",
              " 'pretty': 0.03571428571428571,\n",
              " 'really': 0.07142857142857142,\n",
              " 'so': 0.03571428571428571,\n",
              " 'super': 0.03571428571428571,\n",
              " 'tiny': 0.03571428571428571,\n",
              " 'why': 0.03571428571428571,\n",
              " 'your': 0.03571428571428571}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBWRVJ0sXHiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# starting words\n",
        "text = [\"the\", \"food\"]\n",
        "sentence_finished = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L89Tt-59XHiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while not sentence_finished:\n",
        "  counter=0.0\n",
        "  threshold= random.random()\n",
        "  last_two_words=tuple(text[-2:])\n",
        "  for word in model[last_two_words].keys():\n",
        "    counter += model[last_two_words][word]\n",
        "\n",
        "    if counter>= threshold:\n",
        "      text.append(word)\n",
        "  if text[-2]==[None,None]:\n",
        "    sentence_finished= True"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}